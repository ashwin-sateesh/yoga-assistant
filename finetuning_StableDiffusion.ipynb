{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih7oKKn8rbzt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "#!pip install datasets"
      ],
      "metadata": {
        "id": "7jP8p8gkscWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import torch\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "3SLFlIUescTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "OvnI4GlSswuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "Xx-zTNCrrsHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = \"/content/drive/MyDrive/yoga_bot/dataset/\"\n",
        "yoga_names = os.listdir(main_dir)[1:]  # Skipping the first element if it's not a directory\n",
        "\n",
        "# Function to create visualization-focused text prompts\n",
        "def create_prompts(yoga_pose_name):\n",
        "    prompts = [\n",
        "        f\"Describe the {yoga_pose_name} pose.\",\n",
        "        f\"How does the {yoga_pose_name} pose look?\",\n",
        "        f\"Imagine the {yoga_pose_name} pose. What does it look like?\",\n",
        "        f\"Visualize the {yoga_pose_name} pose and describe its details.\",\n",
        "        f\"Picture someone in the {yoga_pose_name} pose. How do they look?\",\n",
        "        f\"What is the {yoga_pose_name} pose?\",\n",
        "        f\"Describe the key features of the {yoga_pose_name} pose.\",\n",
        "        f\"How would you visualize the {yoga_pose_name} pose?\",\n",
        "        f\"Think about the {yoga_pose_name} pose. What do you see?\",\n",
        "        f\"Provide a visual description of the {yoga_pose_name} pose.\"\n",
        "    ]\n",
        "    return prompts\n",
        "\n",
        "# Dictionary to store yoga poses and their respective prompts\n",
        "yoga_prompts = {}\n",
        "for yoga_pose_name in yoga_names:\n",
        "    yoga_prompts[yoga_pose_name] = create_prompts(yoga_pose_name)"
      ],
      "metadata": {
        "id": "FNJMG6tGrirh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create train-validation split\n",
        "def text_img_pairs(main_dir, yoga_prompts):\n",
        "    data_pairs = []\n",
        "\n",
        "    for yoga_pose_name, prompts in yoga_prompts.items():\n",
        "        img_dir = os.path.join(main_dir, yoga_pose_name)\n",
        "        img_list = os.listdir(img_dir)\n",
        "\n",
        "        # Create (prompt, image_path) pairs in a balanced way\n",
        "        for i, img in enumerate(img_list):\n",
        "            prompt = prompts[i % len(prompts)]\n",
        "            image_path = os.path.join(img_dir, img)\n",
        "            data_pairs.append((prompt, image_path))\n",
        "\n",
        "    return data_pairs\n",
        "\n",
        "data_pairs = text_img_pairs(main_dir, yoga_prompts)"
      ],
      "metadata": {
        "id": "xIUrVn6Nrinv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating new datafolder and metadata for finetuning"
      ],
      "metadata": {
        "id": "Jb3Dwp3ssDFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dcumentation about dataformat to tune: https://huggingface.co/docs/datasets/v2.4.0/en/image_load#imagefolder-with-metadata"
      ],
      "metadata": {
        "id": "a_BjEV8itw-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the destination directory exists\n",
        "destination_dir = '/content/drive/MyDrive/yoga_bot/yoga_img_dataset'\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Path to the metadata file\n",
        "metadata_path = os.path.join(destination_dir, 'metadata.jsonl')\n",
        "\n",
        "# Initialize the metadata list\n",
        "metadata = []\n",
        "\n",
        "# Iterate through the data pairs\n",
        "for prompt, img_path in data_pairs:\n",
        "    # Extract the image file name from the original path\n",
        "    img_name = os.path.basename(img_path)\n",
        "\n",
        "    # Extract the pose name from the image path\n",
        "    pose_name = os.path.basename(os.path.dirname(img_path))\n",
        "\n",
        "    # Define the new image name\n",
        "    new_img_name = f\"{pose_name}_{img_name}\"\n",
        "\n",
        "    # Define the new image path\n",
        "    new_img_path = os.path.join(destination_dir, new_img_name)\n",
        "\n",
        "    # Copy the image to the new directory\n",
        "    shutil.copy(img_path, new_img_path)\n",
        "\n",
        "    # Create a metadata entry\n",
        "    metadata.append({\"file_name\": new_img_name, \"text\": prompt})\n",
        "\n",
        "# Write the metadata to the JSONL file\n",
        "with open(metadata_path, 'w') as f:\n",
        "    for entry in metadata:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "m8i0G41ZrilR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone the Diffusers from HuggingFace Repo"
      ],
      "metadata": {
        "id": "JTvL_HGps1rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Documentation for text-to-image tuning : https://github.com/huggingface/diffusers/tree/main/examples/text_to_image"
      ],
      "metadata": {
        "id": "z86K75h7tjom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "id": "IXQjcMwkriiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -r /content/diffusers/examples/text_to_image/requirements.txt"
      ],
      "metadata": {
        "id": "7TD9x8N5rige"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "id": "wHeJ3ScTtKV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imagefolder\", data_dir=\"/content/drive/MyDrive/yoga_bot/yoga_img_dataset\", drop_labels=True)"
      ],
      "metadata": {
        "id": "Fc11Rv_OrieG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MODEL_NAME'] = \"CompVis/stable-diffusion-v1-4\"\n",
        "os.environ['DATASET_NAME'] = \"/content/drive/MyDrive/yoga_bot/yoga_img_dataset\"\n",
        "os.environ['OUTPUT_DIR'] = \"/content/drive/MyDrive/yoga_bot/yoga-stable-diffusion-v1-4-model\"\n",
        "os.environ['TRAIN_DIR'] = \"/content/drive/MyDrive/yoga_bot/yoga_img_dataset\"\n",
        "os.environ['OUTPUT_DIR1'] = \"/content/drive/MyDrive/yoga_bot/yoga-stable-diffusion-v1-4-model-3000st\""
      ],
      "metadata": {
        "id": "AXIRxdjJriby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\" /content/diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --use_ema \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --output_dir=$OUTPUT_DIR1"
      ],
      "metadata": {
        "id": "04ZMZQiUriZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afi188sdriXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kzdKnP1riU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}